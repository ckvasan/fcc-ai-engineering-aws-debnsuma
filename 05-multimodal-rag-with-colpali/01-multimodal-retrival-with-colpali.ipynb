{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colpali_engine.models import ColQwen2, ColQwen2Processor\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model and processor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA/MPS is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"vidore/colqwen2-v0.1\"\n",
    "model = ColQwen2.from_pretrained(\n",
    "                pretrained_model_name_or_path=model_name,\n",
    "                torch_dtype=torch.bfloat16,\n",
    "                device_map=device, \n",
    "                cache_dir=\"./model_cache\"\n",
    "            )\n",
    "\n",
    "processor = ColQwen2Processor.from_pretrained(\n",
    "                pretrained_model_name_or_path=model_name,\n",
    "                cache_dir=\"./model_cache\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the model to evaluation mode\n",
    "model.eval()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Downloading the dataset \n",
    "url = \"https://reseauactionclimat.org/wp-content/uploads/2018/04/powerpoint-final-kit.pdf\"\n",
    "\n",
    "# Set the filename and filepath\n",
    "filename = \"test.pdf\"\n",
    "filepath = os.path.join(\"data\", filename)\n",
    "\n",
    "# Create the data directory if it doesn't exist\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with open(filepath, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"File downloaded successfully: {filepath}\")\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local file path\n",
    "filepath = \"data/lec_04.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting PDF to Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "import pymupdf\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Define the function to process each page of the PDF\n",
    "def process_page_images(page, page_num, base_dir):\n",
    "    # Create a pixmap from the PDF page\n",
    "    pix = page.get_pixmap()\n",
    "\n",
    "    # Define the path where the image will be saved\n",
    "    page_path = os.path.join(base_dir, f\"page_{page_num:03d}.jpeg\")\n",
    "\n",
    "    # Save the pixmap as a JPEG image\n",
    "    pix.save(page_path)\n",
    "\n",
    "    # Open the saved image file and convert it to a base64 string\n",
    "    with open(page_path, 'rb') as file:\n",
    "        encoded_image = base64.b64encode(file.read()).decode('utf8')\n",
    "\n",
    "    # Convert the base64 string back to a bytes object and create a PIL image\n",
    "    image_data = BytesIO(base64.b64decode(encoded_image))\n",
    "    page_image_pil = Image.open(image_data)\n",
    "\n",
    "    # Return the PIL image object\n",
    "    return page_image_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pymupdf.open(filepath)\n",
    "num_pages = len(doc)\n",
    "output_dir = \"data/processed_page_images\"\n",
    "\n",
    "images = []\n",
    "\n",
    "# Make sure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process each page of the PDF\n",
    "for page_num in tqdm(range(num_pages), desc=\"Processing PDF pages\"):\n",
    "    page = doc[page_num]\n",
    "    image = process_page_images(page, page_num, output_dir)\n",
    "    images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the images into a dataloader\n",
    "\n",
    "dataloader = DataLoader(\n",
    "                            dataset=images,\n",
    "                            batch_size=2,\n",
    "                            shuffle=False,\n",
    "                            collate_fn=lambda x: processor.process_images(x),\n",
    "                        )\n",
    "\n",
    "ds  = []\n",
    "for batch_doc in tqdm(dataloader):\n",
    "    with torch.no_grad():\n",
    "        batch_doc = {k: v.to(model.device) for k, v in batch_doc.items()}\n",
    "        embeddings_doc = model(**batch_doc)\n",
    "    ds.extend(list(torch.unbind(embeddings_doc.to(\"cpu\"))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(query: str):\n",
    "    batch_queries = processor.process_queries([query]).to(model.device)\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        query_embeddings = model(**batch_queries)\n",
    "\n",
    "    scores = processor.score_multi_vector(query_embeddings, ds)\n",
    "    # get top-5 scores\n",
    "    return scores[0].topk(5).indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display and resize keepin aspect ratio\n",
    "\n",
    "query = \"What animals are in danger with climate change ?\"\n",
    "\n",
    "idx = get_results(query)[0]\n",
    "im = images[idx]\n",
    "\n",
    "def display_resize(im):\n",
    "    shrink_factor = (im.size[0]/1024)\n",
    "    display(im.resize((int(im.size[0]/shrink_factor), int(im.size[1]/shrink_factor))))\n",
    "\n",
    "display_resize(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colpali_engine.interpretability import (\n",
    "    get_similarity_maps_from_embeddings,\n",
    "    plot_all_similarity_maps,\n",
    "    plot_similarity_map,\n",
    ")\n",
    "\n",
    "\n",
    "# Get the number of image patches\n",
    "n_patches = processor.get_n_patches(\n",
    "    image_size=im.size,\n",
    "    patch_size=model.patch_size,\n",
    "    spatial_merge_size=model.spatial_merge_size,\n",
    ")\n",
    "\n",
    "\n",
    "# Get the tensor mask to filter out the embeddings that are not related to the image\n",
    "image_mask = processor.get_image_mask(processor.process_images([im]))\n",
    "\n",
    "batch_queries = processor.process_queries([\"What animals are in danger with climate change ?\"]).to(model.device)\n",
    "# Generate the similarity maps\n",
    "batched_similarity_maps = get_similarity_maps_from_embeddings(\n",
    "    image_embeddings=ds[idx].unsqueeze(0).to(model.device),\n",
    "    query_embeddings=model(**batch_queries),\n",
    "    n_patches=n_patches,\n",
    "    image_mask=image_mask,\n",
    ")\n",
    "\n",
    "query_content = processor.decode(batch_queries.input_ids[0]).replace(processor.tokenizer.pad_token, \"\")\n",
    "query_content = query_content.replace(processor.query_augmentation_token, \"\").strip()\n",
    "query_tokens = processor.tokenizer.tokenize(query_content)\n",
    "\n",
    "# Get the similarity map for our (only) input image\n",
    "similarity_maps = batched_similarity_maps[0]  # (query_length, n_patches_x, n_patches_y)\n",
    "\n",
    "\n",
    "token_idx = 3 # for the third token\n",
    "\n",
    "fig, ax = plot_similarity_map(\n",
    "    image=im,\n",
    "    similarity_map=similarity_maps[token_idx],\n",
    "    figsize=(8, 8),\n",
    "    show_colorbar=False,\n",
    ")\n",
    "\n",
    "max_sim_score = similarity_maps[token_idx, :, :].max().item()\n",
    "ax.set_title(f\"Token #{token_idx}: `{query_tokens[token_idx].replace('Ä ', '_')}`. MaxSim score: {max_sim_score:.2f}\", fontsize=14)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def cleanup_memory():\n",
    "    \"\"\"Clean up memory by deleting variables and running garbage collection for CPU, CUDA, or MPS\"\"\"\n",
    "    import gc\n",
    "    \n",
    "    variables_to_clean = [\n",
    "        'query_content',\n",
    "        'query_tokens',\n",
    "        'batch_queries',\n",
    "        'batched_similarity_maps',\n",
    "        'similarity_maps',\n",
    "        'image_mask',\n",
    "        'n_patches',\n",
    "        'im'\n",
    "    ]\n",
    "    \n",
    "    # Delete variables if they exist in global scope\n",
    "    for var in variables_to_clean:\n",
    "        if var in globals():\n",
    "            del globals()[var]\n",
    "    \n",
    "    # Force garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "    # Clear CUDA cache if using CUDA\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "    \n",
    "    # Clear MPS cache if using MPS (Apple Silicon)\n",
    "    if hasattr(torch.mps, 'empty_cache'):  # Check if MPS is available\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "    # Delete the processed folder\n",
    "    if os.path.exists(\"data/processed_page_images\"):\n",
    "        shutil.rmtree(\"data/processed_page_images\")\n",
    "\n",
    "    # Delete the model cache\n",
    "    if os.path.exists(\"model_cache\"):\n",
    "        shutil.rmtree(\"model_cache\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cleanup\n",
    "cleanup_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
